{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8f0f55-a60e-40be-9443-39b409f5c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import ssd300_vgg16\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, cohen_kappa_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7282f1-afb8-4140-b1b7-2c28d21e425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.label_dir = Path(label_dir)\n",
    "        self.images = sorted(list(self.img_dir.glob(\"*.png\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label_path = self.label_dir / (img_path.stem + \".txt\")\n",
    "        \n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        try:\n",
    "            with open(label_path, \"r\") as f:\n",
    "                line = f.readline().strip().split()\n",
    "                if not line:\n",
    "                    return None\n",
    "                class_id, x, y, w, h = map(float, line)\n",
    "                x_min = (x - w/2) * 300\n",
    "                y_min = (y - h/2) * 300\n",
    "                x_max = (x + w/2) * 300\n",
    "                y_max = (y + h/2) * 300\n",
    "                if x_max <= x_min or y_max <= y_min:\n",
    "                    return None\n",
    "                target = {\n",
    "                    \"boxes\": torch.tensor([[x_min, y_min, x_max, y_max]], dtype=torch.float32),\n",
    "                    \"labels\": torch.tensor([int(class_id)], dtype=torch.int64)\n",
    "                }\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f86ec0c-9da5-4710-b745-19033b099d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return [], []\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    return images, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad63a779-3112-4bb3-a720-8caa07e2114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2Backbone(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = mobilenet_v2(weights=\"DEFAULT\")\n",
    "        self.features = base.features\n",
    "        \n",
    "        self.stage1 = torch.nn.Sequential(*base.features[0:7])   # 38x38, 32 channels\n",
    "        self.stage2 = torch.nn.Sequential(*base.features[7:11])  # 19x19, 64 channels\n",
    "        self.stage3 = torch.nn.Sequential(*base.features[11:18]) # 10x10, 320 channels\n",
    "        \n",
    "        self.extra = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(320, 256, 3, stride=2, padding=1), # 5x5\n",
    "            torch.nn.Conv2d(256, 256, 3, stride=2, padding=1), # 3x3\n",
    "            torch.nn.Conv2d(256, 256, 3, stride=2, padding=0)  # 1x1\n",
    "        ])\n",
    "        \n",
    "        self.adjust_channels = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(32, 512, 1),  # 38x38\n",
    "            torch.nn.Conv2d(64, 512, 1),  # 19x19\n",
    "            torch.nn.Conv2d(320, 512, 1), # 10x10\n",
    "            torch.nn.Conv2d(256, 256, 1), # 5x5\n",
    "            torch.nn.Conv2d(256, 256, 1), # 3x3\n",
    "            torch.nn.Conv2d(256, 256, 1)  # 1x1\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = {}\n",
    "        f1 = self.stage1(x)\n",
    "        f2 = self.stage2(f1)\n",
    "        f3 = self.stage3(f2)\n",
    "        \n",
    "        features[\"0\"] = self.adjust_channels[0](f1)\n",
    "        features[\"1\"] = self.adjust_channels[1](f2)\n",
    "        features[\"2\"] = self.adjust_channels[2](f3)\n",
    "        \n",
    "        x = f3\n",
    "        for i, layer in enumerate(self.extra):\n",
    "            x = layer(x)\n",
    "            features[str(i + 3)] = self.adjust_channels[i + 3](x)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495eb193-f0cb-47aa-bb62-0f35e5dcf872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): MobileNetV2Backbone(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "    )\n",
       "    (adjust_channels): ModuleList(\n",
       "      (0): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(320, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3-5): 3 x Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1-2): 2 x Conv2d(512, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1-2): 2 x Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training script\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = MURADataset(\n",
    "    \"D:/Sem 6 project/MURA_YOLO/train/images\",\n",
    "    \"D:/Sem 6 project/MURA_YOLO/train/labels\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Pre-filter dataset to only include valid image-label pairs\n",
    "filtered_indices = []\n",
    "for idx in range(len(train_dataset)):\n",
    "    try:\n",
    "        item = train_dataset[idx]\n",
    "        if item is not None:\n",
    "            filtered_indices.append(idx)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, filtered_indices)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,  # Kept at 64 for better GPU utilization\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows; try 2 if on Linux\n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Prepare the model\n",
    "device = torch.device(\"cuda\")\n",
    "model = ssd300_vgg16(weights=None)\n",
    "model.backbone = MobileNetV2Backbone()\n",
    "\n",
    "# Create a dummy input to get feature map sizes\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.zeros(1, 3, 300, 300).to(device)\n",
    "    features = model.backbone.to(device)(dummy_input)\n",
    "    in_channels = [features[k].shape[1] for k in features.keys()]\n",
    "\n",
    "# Modify classification and regression heads\n",
    "model.head.classification_head = SSDClassificationHead(\n",
    "    in_channels, \n",
    "    model.anchor_generator.num_anchors_per_location(), \n",
    "    num_classes=15  # 14 classes + background\n",
    ").to(device)\n",
    "\n",
    "model.head.regression_head = SSDRegressionHead(\n",
    "    in_channels, \n",
    "    model.anchor_generator.num_anchors_per_location()\n",
    ").to(device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec3ff5f-f2e8-4b92-8f12-a000abc33ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16048\\3089452851.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|████████████████████████| 576/576 [11:09<00:00,  1.16s/it, loss=0.7160, acc=0.6667, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Avg Loss: 0.3488, Avg Accuracy: 0.7880\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch11.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|████████████████████████| 576/576 [11:51<00:00,  1.24s/it, loss=1.0367, acc=0.8333, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Avg Loss: 0.3166, Avg Accuracy: 0.8039\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch12.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|████████████████████████| 576/576 [11:44<00:00,  1.22s/it, loss=0.7169, acc=0.8333, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Avg Loss: 0.2862, Avg Accuracy: 0.8174\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch13.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|████████████████████████| 576/576 [11:30<00:00,  1.20s/it, loss=0.5309, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Avg Loss: 0.2518, Avg Accuracy: 0.8299\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch14.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|████████████████████████| 576/576 [11:48<00:00,  1.23s/it, loss=0.3053, acc=0.8333, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Avg Loss: 0.2197, Avg Accuracy: 0.8446\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch15.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|████████████████████████| 576/576 [11:33<00:00,  1.20s/it, loss=0.8660, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Avg Loss: 0.1913, Avg Accuracy: 0.8595\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch16.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|████████████████████████| 576/576 [11:33<00:00,  1.20s/it, loss=0.8261, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Avg Loss: 0.1617, Avg Accuracy: 0.8730\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch17.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|████████████████████████| 576/576 [11:47<00:00,  1.23s/it, loss=0.5762, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Avg Loss: 0.1289, Avg Accuracy: 0.8823\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch18.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|████████████████████████| 576/576 [11:37<00:00,  1.21s/it, loss=1.0071, acc=0.8333, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Avg Loss: 0.1159, Avg Accuracy: 0.8887\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch19.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|████████████████████████| 576/576 [13:14<00:00,  1.38s/it, loss=0.3414, acc=0.8333, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Avg Loss: 0.1006, Avg Accuracy: 0.8925\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch20.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|████████████████████████| 576/576 [11:26<00:00,  1.19s/it, loss=0.0107, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Avg Loss: 0.0831, Avg Accuracy: 0.8994\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch21.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|████████████████████████| 576/576 [11:27<00:00,  1.19s/it, loss=0.1868, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Avg Loss: 0.0775, Avg Accuracy: 0.9032\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch22.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|████████████████████████| 576/576 [10:16<00:00,  1.07s/it, loss=1.0130, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Avg Loss: 0.0715, Avg Accuracy: 0.9054\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch23.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|████████████████████████| 576/576 [11:17<00:00,  1.18s/it, loss=1.1727, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Avg Loss: 0.0611, Avg Accuracy: 0.9081\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch24.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|████████████████████████| 576/576 [11:36<00:00,  1.21s/it, loss=0.5875, acc=1.0000, mem=0.12/11.43GB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Avg Loss: 0.0599, Avg Accuracy: 0.9101\n",
      "Saved checkpoint: D:\\Sem 6 project\\checkpoints\\ssd_mobilenetv2_mura_epoch25.pt\n",
      "Saved latest checkpoint: D:\\Sem 6 project\\checkpoints\\latest_checkpoint.pt\n",
      "Final model saved\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and Training Loop\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.9, weight_decay=0.0005)\n",
    "checkpoint_dir = Path(\"D:/Sem 6 project/checkpoints\")\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Check for existing checkpoint to resume\n",
    "start_epoch = 0\n",
    "checkpoint_path = checkpoint_dir / \"latest_checkpoint.pt\"\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"Resuming from checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found, starting from epoch 1\")\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            if not images or len(images) != len(targets):\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                # Compute loss in training mode\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss_dict.values())\n",
    "                \n",
    "                # Compute predictions in evaluation mode for accuracy\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    preds = model(images)\n",
    "                    model.train()\n",
    "                    \n",
    "                    batch_accuracy = 0\n",
    "                    for pred, target in zip(preds, targets):\n",
    "                        pred_labels = pred['labels']\n",
    "                        pred_scores = pred['scores']\n",
    "                        gt_labels = target['labels']\n",
    "                        if len(pred_labels) > 0:\n",
    "                            max_score_idx = torch.argmax(pred_scores)\n",
    "                            pred_label = pred_labels[max_score_idx]\n",
    "                            batch_accuracy += (pred_label == gt_labels[0]).float().mean().item()\n",
    "                        else:\n",
    "                            batch_accuracy += 0  # No predictions, count as incorrect\n",
    "                    batch_accuracy /= len(targets) if len(targets) > 0 else 1\n",
    "                \n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += losses.item()\n",
    "                total_accuracy += batch_accuracy\n",
    "                batch_count += 1\n",
    "                \n",
    "                allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                reserved = torch.cuda.memory_reserved() / 1e9\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f\"{losses.item():.4f}\",\n",
    "                    'acc': f\"{batch_accuracy:.4f}\",\n",
    "                    'mem': f\"{allocated:.2f}/{reserved:.2f}GB\"\n",
    "                })\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Training error in batch {batch_idx+1}: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "            finally:\n",
    "                pbar.update(1)\n",
    "    \n",
    "    avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "    avg_accuracy = total_accuracy / batch_count if batch_count > 0 else 0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {avg_loss:.4f}, Avg Accuracy: {avg_accuracy:.4f}\")\n",
    "    \n",
    "    # Save checkpoint for the epoch\n",
    "    checkpoint_path = checkpoint_dir / f\"ssd_mobilenetv2_mura_epoch{epoch+1}.pt\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Save latest checkpoint for resuming\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_dir / \"latest_checkpoint.pt\")\n",
    "    print(f\"Saved latest checkpoint: {checkpoint_dir / 'latest_checkpoint.pt'}\")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), \"D:/Sem 6 project/ssd_mobilenetv2_mura_final.pt\")\n",
    "print(\"Final model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb77d6c-e264-468a-811e-6aa5c4fc6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Validation Dataset\n",
    "valid_dataset = MURADataset(\n",
    "    \"D:/Sem 6 project/MURA_YOLO/valid/images\",  # Adjust path to your validation images\n",
    "    \"D:/Sem 6 project/MURA_YOLO/valid/labels\",   # Adjust path to your validation labels\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a15b97-e17f-46c5-b27b-03134f6d6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filter validation dataset\n",
    "filtered_indices = []\n",
    "for idx in range(len(valid_dataset)):\n",
    "    try:\n",
    "        item = valid_dataset[idx]\n",
    "        if item is not None:\n",
    "            filtered_indices.append(idx)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "valid_dataset = torch.utils.data.Subset(valid_dataset, filtered_indices)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5362f02-125f-4e17-88fc-084f5e936a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16048\\135777258.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from D:/Sem 6 project/ssd_mobilenetv2_mura_final.pt\n",
      "\n",
      "Evaluating on Training Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval on Train: 100%|█████████████████████████████████████████████████████| 576/576 [06:51<00:00,  1.40it/s, acc=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Metrics:\n",
      "1. Precision: 0.9205\n",
      "2. Recall: 1.0000\n",
      "3. F1 Score: 0.9586\n",
      "4. Accuracy: 0.9148\n",
      "5. Specificity: 0.0000\n",
      "6. G-Mean: 0.0000\n",
      "7. AUC (ROC-AUC): 0.5047\n",
      "8. MCC: 0.9116\n",
      "9. Cohen's Kappa: 0.9057\n",
      "10. Log Loss: 0.3939\n",
      "\n",
      "Evaluating on Validation Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval on Valid: 100%|███████████████████████████████████████████████████████| 50/50 [00:36<00:00,  1.38it/s, acc=0.7049]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Evaluation Metrics:\n",
      "1. Precision: 0.9265\n",
      "2. Recall: 1.0000\n",
      "3. F1 Score: 0.9618\n",
      "4. Accuracy: 0.6832\n",
      "5. Specificity: 0.0000\n",
      "6. G-Mean: 0.0000\n",
      "7. AUC (ROC-AUC): 0.3851\n",
      "8. MCC: 0.6609\n",
      "9. Cohen's Kappa: 0.6564\n",
      "10. Log Loss: 0.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model weights\n",
    "model_path = \"D:/Sem 6 project/ssd_mobilenetv2_mura_final.pt\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "# Evaluation Function with the 10 Metrics\n",
    "def evaluate(model, data_loader, device, desc=\"Evaluating\"):\n",
    "    model.eval()\n",
    "    total_accuracy = 0\n",
    "    batch_count = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    total_log_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(data_loader), desc=desc) as pbar:\n",
    "            for batch_idx, (images, targets) in enumerate(data_loader):\n",
    "                if not images or len(images) != len(targets):\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    images = [img.to(device) for img in images]\n",
    "                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                    # Compute predictions\n",
    "                    preds = model(images)\n",
    "\n",
    "                    # Compute accuracy\n",
    "                    batch_accuracy = 0\n",
    "                    batch_preds = []\n",
    "                    batch_targets = []\n",
    "                    batch_scores = []\n",
    "                    for pred, target in zip(preds, targets):\n",
    "                        pred_labels = pred['labels']\n",
    "                        pred_scores = pred['scores']\n",
    "                        gt_labels = target['labels']\n",
    "                        if len(pred_labels) > 0:\n",
    "                            max_score_idx = torch.argmax(pred_scores)\n",
    "                            pred_label = pred_labels[max_score_idx].item()\n",
    "                            pred_score = pred_scores[max_score_idx].item()\n",
    "                            # Convert boolean to float (1.0 for True, 0.0 for False)\n",
    "                            correct = 1.0 if (pred_label == gt_labels[0].item()) else 0.0\n",
    "                            batch_accuracy += correct\n",
    "                        else:\n",
    "                            pred_label = 0  # Default to background if no predictions\n",
    "                            pred_score = 0.0\n",
    "                            batch_accuracy += 0  # No predictions, count as incorrect\n",
    "                        batch_preds.append(pred_label)\n",
    "                        batch_targets.append(gt_labels[0].item())\n",
    "                        batch_scores.append(pred_score)\n",
    "\n",
    "                    # Compute batch accuracy as the average of correct predictions\n",
    "                    batch_accuracy /= len(targets) if len(targets) > 0 else 1\n",
    "\n",
    "                    # Compute log loss for the batch (simplified for binary classification: foreground vs. background)\n",
    "                    binary_targets = [1 if t > 0 else 0 for t in batch_targets]  # Foreground (1) vs. Background (0)\n",
    "                    binary_probs = torch.sigmoid(torch.tensor(batch_scores, dtype=torch.float)).cpu().numpy()\n",
    "                    # Create a 2D array for log_loss: [P(background), P(foreground)]\n",
    "                    binary_probs_2d = np.vstack([1 - binary_probs, binary_probs]).T\n",
    "                    batch_log_loss = log_loss(binary_targets, binary_probs_2d, labels=[0, 1])\n",
    "                    total_log_loss += batch_log_loss\n",
    "\n",
    "                    all_preds.extend(batch_preds)\n",
    "                    all_targets.extend(batch_targets)\n",
    "                    all_scores.extend(batch_scores)\n",
    "\n",
    "                    total_accuracy += batch_accuracy\n",
    "                    batch_count += 1\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'acc': f\"{batch_accuracy:.4f}\"\n",
    "                    })\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Evaluation error in batch {batch_idx+1}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "    # Compute average accuracy\n",
    "    avg_accuracy = total_accuracy / batch_count if batch_count > 0 else 0\n",
    "    avg_log_loss = total_log_loss / batch_count if batch_count > 0 else 0\n",
    "\n",
    "    # Convert predictions and targets to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_scores = np.array(all_scores)\n",
    "\n",
    "    # Compute confusion matrix components (TP, TN, FP, FN)\n",
    "    # For simplicity, we'll treat this as a binary classification problem (foreground vs. background)\n",
    "    # Foreground: any class > 0, Background: class 0\n",
    "    true_positives = np.sum((all_preds > 0) & (all_targets > 0))\n",
    "    true_negatives = np.sum((all_preds == 0) & (all_targets == 0))\n",
    "    false_positives = np.sum((all_preds > 0) & (all_targets == 0))\n",
    "    false_negatives = np.sum((all_preds == 0) & (all_targets > 0))\n",
    "\n",
    "    # Compute Precision, Recall, F1 Score\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Compute Specificity\n",
    "    specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "\n",
    "    # Compute G-Mean\n",
    "    g_mean = np.sqrt(recall * specificity) if (recall * specificity) > 0 else 0\n",
    "\n",
    "    # Compute AUC (ROC-AUC)\n",
    "    # For multiclass, we use one-vs-rest AUC; here we simplify to foreground vs. background\n",
    "    binary_targets = (all_targets > 0).astype(int)\n",
    "    binary_scores = np.array(all_scores)  # Use scores for foreground probability\n",
    "    auc = roc_auc_score(binary_targets, binary_scores) if len(np.unique(binary_targets)) > 1 else 0\n",
    "\n",
    "    # Compute MCC (Matthews Correlation Coefficient)\n",
    "    mcc = matthews_corrcoef(all_targets, all_preds)\n",
    "\n",
    "    # Compute Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": avg_accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"g_mean\": g_mean,\n",
    "        \"auc\": auc,\n",
    "        \"mcc\": mcc,\n",
    "        \"kappa\": kappa,\n",
    "        \"log_loss\": avg_log_loss\n",
    "    }\n",
    "\n",
    "# Evaluate on Training Set\n",
    "print(\"\\nEvaluating on Training Set:\")\n",
    "train_metrics = evaluate(model, train_loader, device, desc=\"Eval on Train\")\n",
    "print(\"Train Evaluation Metrics:\")\n",
    "print(f\"1. Precision: {train_metrics['precision']:.4f}\")\n",
    "print(f\"2. Recall: {train_metrics['recall']:.4f}\")\n",
    "print(f\"3. F1 Score: {train_metrics['f1']:.4f}\")\n",
    "print(f\"4. Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "print(f\"5. Specificity: {train_metrics['specificity']:.4f}\")\n",
    "print(f\"6. G-Mean: {train_metrics['g_mean']:.4f}\")\n",
    "print(f\"7. AUC (ROC-AUC): {train_metrics['auc']:.4f}\")\n",
    "print(f\"8. MCC: {train_metrics['mcc']:.4f}\")\n",
    "print(f\"9. Cohen's Kappa: {train_metrics['kappa']:.4f}\")\n",
    "print(f\"10. Log Loss: {train_metrics['log_loss']:.4f}\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "valid_metrics = evaluate(model, valid_loader, device, desc=\"Eval on Valid\")\n",
    "print(\"Validation Evaluation Metrics:\")\n",
    "print(f\"1. Precision: {valid_metrics['precision']:.4f}\")\n",
    "print(f\"2. Recall: {valid_metrics['recall']:.4f}\")\n",
    "print(f\"3. F1 Score: {valid_metrics['f1']:.4f}\")\n",
    "print(f\"4. Accuracy: {valid_metrics['accuracy']:.4f}\")\n",
    "print(f\"5. Specificity: {valid_metrics['specificity']:.4f}\")\n",
    "print(f\"6. G-Mean: {valid_metrics['g_mean']:.4f}\")\n",
    "print(f\"7. AUC (ROC-AUC): {valid_metrics['auc']:.4f}\")\n",
    "print(f\"8. MCC: {valid_metrics['mcc']:.4f}\")\n",
    "print(f\"9. Cohen's Kappa: {valid_metrics['kappa']:.4f}\")\n",
    "print(f\"10. Log Loss: {valid_metrics['log_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66b553f-f52e-4836-b863-4bb28f85b046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded autoencoder checkpoint from D:\\Sem 6 project\\checkpoints-BAGAN-GP-WGAN-GP_Old-2\\autoencoder_epoch_50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating autoencoder samples:  81%|██████████████████████████████████████▊         | 323/400 [00:57<00:13,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved autoencoder samples to autoencoder_samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 512\n",
    "LATENT_DIM = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 14\n",
    "DATASET_DIR = 'MURA-v1.1/valid'  # Update this path to your dataset directory\n",
    "CHECKPOINT_DIR = 'D:\\\\Sem 6 project\\\\checkpoints-BAGAN-GP-WGAN-GP_Old-2'  # Update this path to your checkpoint directory\n",
    "OUTPUT_DIR = 'autoencoder_samples'  # Update this path for saving output samples\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "body_parts = ['XR_WRIST', 'XR_SHOULDER', 'XR_HAND', 'XR_FOREARM', 'XR_FINGER', 'XR_ELBOW', 'XR_HUMERUS']\n",
    "case_types = ['positive', 'negative']\n",
    "class_names = [f\"{bp}_{ct}\" for bp in body_parts for ct in case_types]\n",
    "\n",
    "class MURADataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            full_path = os.path.join(DATASET_DIR, '..', img_path)\n",
    "            image = Image.open(full_path).convert('L')  # Grayscale for X-rays\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            label = self.labels[idx]\n",
    "            label_onehot = torch.zeros(NUM_CLASSES)\n",
    "            label_onehot[label] = 1.0\n",
    "            return image, label_onehot\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Instead of returning a placeholder, raise an exception to skip invalid images\n",
    "            raise e\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, stride=2, padding=1),  # 512 -> 256\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 256 -> 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 128 -> 64\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),  # 64 -> 32\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1024, 4, stride=2, padding=1),  # 32 -> 16\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Linear(1024 * 16 * 16, LATENT_DIM)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        latent = self.fc(x)\n",
    "        return latent\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.initial_size = 16\n",
    "        # Modified to match the original notebook's architecture for checkpoint compatibility\n",
    "        self.fc = nn.Linear(LATENT_DIM + NUM_CLASSES, 1024 * self.initial_size * self.initial_size)\n",
    "        self.bn_initial = nn.BatchNorm2d(1024)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1),  # 16 -> 32\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),  # 32 -> 64\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 64 -> 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 128 -> 256\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1),  # 256 -> 512\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        # Concatenate latent vector with labels instead of multiplication\n",
    "        x = torch.cat([z, labels], dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 1024, self.initial_size, self.initial_size)\n",
    "        x = self.bn_initial(x)\n",
    "        x = nn.functional.relu(x, inplace=True)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent, labels)\n",
    "        return reconstructed\n",
    "\n",
    "def scan_dataset(dataset_dir=DATASET_DIR):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for root, _, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(full_path, os.path.join(dataset_dir, '..'))\n",
    "                label = None\n",
    "                for bp in body_parts:\n",
    "                    if bp in relative_path:\n",
    "                        case = 'positive' if 'positive' in relative_path else 'negative'\n",
    "                        class_idx = body_parts.index(bp) * 2 + (0 if case == 'positive' else 1)\n",
    "                        label = class_idx\n",
    "                        break\n",
    "                if label is not None:\n",
    "                    image_paths.append(relative_path)\n",
    "                    labels.append(label)\n",
    "    return np.array(image_paths), np.array(labels)\n",
    "\n",
    "# Load validation dataset\n",
    "val_paths, val_labels = scan_dataset()\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "val_dataset = MURADataset(val_paths, val_labels, transform=val_transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Load autoencoder\n",
    "autoencoder = Autoencoder(NUM_CLASSES).to(device)\n",
    "checkpoint_path = os.path.join(CHECKPOINT_DIR, 'autoencoder_epoch_50.pth')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    autoencoder.load_state_dict(torch.load(checkpoint_path, map_location=device, weights_only=True))\n",
    "    print(f\"Loaded autoencoder checkpoint from {checkpoint_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "\n",
    "def generate_autoencoder_samples(autoencoder, dataloader, num_samples_per_class=1):\n",
    "    autoencoder.eval()\n",
    "    class_samples = {i: [] for i in range(NUM_CLASSES)}\n",
    "    class_counts = {i: 0 for i in range(NUM_CLASSES)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating autoencoder samples\"):\n",
    "            try:\n",
    "                images, labels_onehot = batch\n",
    "                images = images.to(device)\n",
    "                labels_onehot = labels_onehot.to(device)\n",
    "                labels = torch.argmax(labels_onehot, dim=1)\n",
    "\n",
    "                reconstructed = autoencoder(images, labels_onehot)\n",
    "\n",
    "                images = (images + 1) / 2  # Denormalize from [-1, 1] to [0, 1]\n",
    "                reconstructed = (reconstructed + 1) / 2\n",
    "\n",
    "                for i in range(images.size(0)):\n",
    "                    class_idx = labels[i].item()\n",
    "                    if class_counts[class_idx] < num_samples_per_class:\n",
    "                        class_samples[class_idx].append((images[i], reconstructed[i]))\n",
    "                        class_counts[class_idx] += 1\n",
    "\n",
    "                if all(count >= num_samples_per_class for count in class_counts.values()):\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Plot and save samples\n",
    "    fig, axes = plt.subplots(NUM_CLASSES, 2, figsize=(8, NUM_CLASSES * 2))\n",
    "    for class_idx in range(NUM_CLASSES):\n",
    "        if class_samples[class_idx]:\n",
    "            real_img, recon_img = class_samples[class_idx][0]\n",
    "            real_img = real_img.cpu().numpy().squeeze()\n",
    "            recon_img = recon_img.cpu().numpy().squeeze()\n",
    "\n",
    "            axes[class_idx, 0].imshow(real_img, cmap='gray')\n",
    "            axes[class_idx, 0].set_title(f\"Real: {class_names[class_idx]}\")\n",
    "            axes[class_idx, 0].axis('off')\n",
    "\n",
    "            axes[class_idx, 1].imshow(recon_img, cmap='gray')\n",
    "            axes[class_idx, 1].set_title(f\"Recon: {class_names[class_idx]}\")\n",
    "            axes[class_idx, 1].axis('off')\n",
    "\n",
    "            plt.imsave(\n",
    "                os.path.join(OUTPUT_DIR, f'reconstructed_{class_names[class_idx]}.png'),\n",
    "                recon_img, cmap='gray'\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No samples generated for class {class_names[class_idx]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'autoencoder_samples.png'))\n",
    "    plt.close()\n",
    "    print(f\"Saved autoencoder samples to {OUTPUT_DIR}\")\n",
    "\n",
    "# Generate samples\n",
    "generate_autoencoder_samples(autoencoder, val_dataloader, num_samples_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c9f1d-7b37-471f-8710-7b01f44fddea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

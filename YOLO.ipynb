{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37f0777-7666-4430-ba3b-587923c0c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0242397-237e-4ed4-8519-47641f36d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preparing YOLO dataset...\n",
      "Current working directory: D:\\Sem 6 project\n",
      "âœ… Training CSV found: D:\\Sem 6 project\\MURA-v1.1\\train_image_paths.csv\n",
      "Sample training CSV content:\n",
      "                                                   0\n",
      "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...\n",
      "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study...\n",
      "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study...\n",
      "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study...\n",
      "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study...\n",
      "\n",
      "ðŸ“Š CSV Analysis for train:\n",
      "   - Total entries in CSV: 36808\n",
      "   - Duplicate entries: 0\n",
      "ðŸ”¹ Checking file: D:\\Sem 6 project\\MURA-v1.1\\train\\XR_SHOULDER\\patient00001\\study1_positive\\image1.png\n",
      "   - Exists: True\n",
      "ðŸ”¹ Checking file: D:\\Sem 6 project\\MURA-v1.1\\train\\XR_SHOULDER\\patient00001\\study1_positive\\image2.png\n",
      "   - Exists: True\n",
      "ðŸ”¹ Checking file: D:\\Sem 6 project\\MURA-v1.1\\train\\XR_SHOULDER\\patient00001\\study1_positive\\image3.png\n",
      "   - Exists: True\n",
      "ðŸ”¹ Checking file: D:\\Sem 6 project\\MURA-v1.1\\train\\XR_SHOULDER\\patient00002\\study1_positive\\image1.png\n",
      "   - Exists: True\n",
      "ðŸ”¹ Checking file: D:\\Sem 6 project\\MURA-v1.1\\train\\XR_SHOULDER\\patient00002\\study1_positive\\image2.png\n",
      "   - Exists: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 118\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m     \u001b[43mprepare_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(valid_csv):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Validation CSV file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m, in \u001b[0;36mprepare_yolo_dataset\u001b[1;34m(csv_file, split, label_df)\u001b[0m\n\u001b[0;32m     65\u001b[0m dest_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_dir, filename)\n\u001b[0;32m     66\u001b[0m copied_filenames\u001b[38;5;241m.\u001b[39madd(filename)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m processed_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Create label file\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Get study path from image path\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:258\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m                 _fastcopy_fcopyfile(fsrc, fdst, posix\u001b[38;5;241m.\u001b[39m_COPYFILE_DATA)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset paths\n",
    "base_dir = os.path.abspath(\".\")  # Current working directory: D:\\Sem 6 project\n",
    "data_dir = os.path.join(base_dir, \"MURA-v1.1\")  # D:\\Sem 6 project\\MURA-v1.1\n",
    "yolo_data_dir = os.path.join(base_dir, \"MURA_YOLO\")  # D:\\Sem 6 project\\MURA_YOLO\n",
    "\n",
    "def prepare_yolo_dataset(csv_file, split, label_df):\n",
    "    \"\"\" Converts dataset into YOLO format with improved debugging and label creation. \"\"\"\n",
    "    \n",
    "    # Load CSV with correct column names\n",
    "    df = pd.read_csv(csv_file, header=None, names=[\"image_path\"])\n",
    "    \n",
    "    print(f\"\\nðŸ“Š CSV Analysis for {split}:\")\n",
    "    print(f\"   - Total entries in CSV: {len(df)}\")\n",
    "    \n",
    "    # Check for duplicate entries\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"   - Duplicate entries: {duplicates}\")\n",
    "    \n",
    "    # Create YOLO directory structure\n",
    "    images_dir = os.path.join(yolo_data_dir, split, \"images\")\n",
    "    labels_dir = os.path.join(yolo_data_dir, split, \"labels\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    processed_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    # Track unique filenames to avoid duplicates\n",
    "    copied_filenames = set()\n",
    "    \n",
    "    # Map studies to labels\n",
    "    study_to_label = dict(zip(label_df[\"study_path\"], label_df[\"label\"]))\n",
    "    \n",
    "    # Define body parts and class mapping\n",
    "    body_parts = [\"XR_ELBOW\", \"XR_FINGER\", \"XR_FOREARM\", \"XR_HAND\", \"XR_HUMERUS\", \"XR_SHOULDER\", \"XR_WRIST\"]\n",
    "    class_names = [f\"{bp}_{cond}\" for bp in body_parts for cond in [\"negative\", \"positive\"]]\n",
    "    class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Construct full image path\n",
    "        image_rel_path = row[\"image_path\"]  # e.g., MURA-v1.1/train/XR_SHOULDER/...\n",
    "        image_path = os.path.join(base_dir, image_rel_path)  # D:\\Sem 6 project\\MURA-v1.1\\train\\...\n",
    "        image_path = os.path.normpath(image_path)\n",
    "        \n",
    "        filename = os.path.basename(image_path)\n",
    "        \n",
    "        if index < 5:\n",
    "            print(f\"ðŸ”¹ Checking file: {image_path}\")\n",
    "            print(f\"   - Exists: {os.path.exists(image_path)}\")\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            if missing_count < 10:\n",
    "                print(f\"âš ï¸ Missing file: {image_path}\")\n",
    "            missing_count += 1\n",
    "            continue  \n",
    "\n",
    "        if filename in copied_filenames:\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            filename = f\"{base}_{index}{ext}\"\n",
    "        \n",
    "        dest_image_path = os.path.join(images_dir, filename)\n",
    "        copied_filenames.add(filename)\n",
    "        \n",
    "        shutil.copy(image_path, dest_image_path)\n",
    "        processed_count += 1\n",
    "        \n",
    "        # Create label file\n",
    "        # Get study path from image path\n",
    "        study_path = \"/\".join(image_rel_path.split(\"/\")[:-1]) + \"/\"  # e.g., MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/\n",
    "        label = study_to_label.get(study_path, None)\n",
    "        if label is None:\n",
    "            print(f\"Warning: No label found for study {study_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract body part from image path\n",
    "        body_part = [bp for bp in body_parts if bp in image_rel_path][0]\n",
    "        condition = \"positive\" if label == 1 else \"negative\"\n",
    "        class_name = f\"{body_part}_{condition}\"\n",
    "        class_id = class_to_id[class_name]\n",
    "        \n",
    "        lbl_name = filename.replace(\".png\", \".txt\")\n",
    "        dest_label_path = os.path.join(labels_dir, lbl_name)\n",
    "        with open(dest_label_path, \"w\") as f:\n",
    "            f.write(f\"{class_id} 0.5 0.5 1.0 1.0\\n\")\n",
    "        \n",
    "        if processed_count % 1000 == 0:\n",
    "            print(f\"âœ… {processed_count} images processed...\")\n",
    "\n",
    "    print(f\"ðŸ“¸ Total {processed_count} images processed for {split}.\")\n",
    "    print(f\"ðŸš¨ Total {missing_count} missing images in {split} set.\")\n",
    "\n",
    "print(\"ðŸ”„ Preparing YOLO dataset...\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"âŒ Data directory not found: {data_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "train_csv = os.path.join(data_dir, \"train_image_paths.csv\")\n",
    "valid_csv = os.path.join(data_dir, \"valid_image_paths.csv\")\n",
    "train_label_df = pd.read_csv(os.path.join(data_dir, \"train_labeled_studies.csv\"), header=None, names=[\"study_path\", \"label\"])\n",
    "valid_label_df = pd.read_csv(os.path.join(data_dir, \"valid_labeled_studies.csv\"), header=None, names=[\"study_path\", \"label\"])\n",
    "\n",
    "if not os.path.exists(train_csv):\n",
    "    print(f\"âŒ Training CSV file not found: {train_csv}\")\n",
    "else:\n",
    "    print(f\"âœ… Training CSV found: {train_csv}\")\n",
    "    try:\n",
    "        train_df = pd.read_csv(train_csv, header=None, nrows=5)\n",
    "        print(\"Sample training CSV content:\")\n",
    "        print(train_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "    prepare_yolo_dataset(train_csv, \"train\", train_label_df)\n",
    "\n",
    "if not os.path.exists(valid_csv):\n",
    "    print(f\"âŒ Validation CSV file not found: {valid_csv}\")\n",
    "else:\n",
    "    print(f\"âœ… Validation CSV found: {valid_csv}\")\n",
    "    prepare_yolo_dataset(valid_csv, \"valid\", valid_label_df)\n",
    "\n",
    "print(\"âœ… Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bce2de-3439-4173-8edf-0de26d71a8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.96 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.94  Python-3.10.11 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=MURA_YOLO/mura.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=1, cache=False, device=0, workers=8, project=runs/train, name=mura_yolov8(25 epoch)73, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\train\\mura_yolov8(25 epoch)73\n",
      "Overriding model.yaml nc=80 with nc=14\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    754042  ultralytics.nn.modules.head.Detect           [14, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,013,578 parameters, 3,013,562 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Sem 6 project\\MURA_YOLO\\train\\labels... 36806 images, 0 backgrounds, 2 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Sem 6 project\\MURA_YOLO\\train\\images\\image1_10713.png: ignoring corrupt image/label: cannot identify image file 'D:\\\\Sem 6 project\\\\MURA_YOLO\\\\train\\\\images\\\\image1_10713.png'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Sem 6 project\\MURA_YOLO\\train\\images\\image1_488.png: ignoring corrupt image/label: cannot identify image file 'D:\\\\Sem 6 project\\\\MURA_YOLO\\\\train\\\\images\\\\image1_488.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Sem 6 project\\MURA_YOLO\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Sem 6 project\\MURA_YOLO\\valid\\labels.cache... 3197 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\train\\mura_yolov8(25 epoch)73\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\mura_yolov8(25 epoch)73\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      2.04G     0.2303      2.047     0.9795         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [05:04<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.526      0.815      0.682      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      3.02G      0.176      1.241     0.9146         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:43<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197        0.6      0.775      0.736      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      3.02G     0.1906      1.081     0.9191         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:51<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197       0.66      0.744      0.743      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      3.02G     0.1708     0.9863     0.9112         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:44<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.652      0.761      0.761      0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      3.02G     0.1394     0.9163     0.8994         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197       0.68       0.79      0.789      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      3.02G     0.1198     0.8709     0.8935         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.742      0.774      0.808      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      3.02G     0.1079     0.8467     0.8893         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.712      0.784      0.805      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      3.02G    0.09933     0.8195     0.8872         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.765      0.778      0.825      0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      3.02G    0.09196     0.8029     0.8841         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.784      0.772      0.835      0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      3.02G    0.08684     0.7856     0.8832         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.763        0.8      0.843      0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      3.02G    0.08106     0.7709     0.8808         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197       0.75      0.821      0.841       0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      3.02G     0.0768     0.7602     0.8794         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.771       0.81      0.848      0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      3.02G    0.07329      0.747     0.8804         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.774      0.813      0.849      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      3.02G     0.0689     0.7348     0.8772         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.785      0.807       0.85      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25      3.02G    0.06634     0.7294     0.8772         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197       0.78      0.813      0.854      0.853\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      3.02G    0.05202     0.5618     0.8639          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [05:14<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.793      0.798      0.854      0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      3.02G        inf     0.5436     0.8593          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:29<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.785      0.809      0.856      0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      3.02G    0.03939     0.5286     0.8586          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.798      0.805      0.859      0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      3.02G    0.03421     0.5147     0.8571          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.807      0.801      0.862      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      3.02G    0.03178     0.5007     0.8564          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:29<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.793      0.816      0.865      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      3.02G    0.02898     0.4902     0.8547          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:29<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.787      0.827      0.866      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      3.02G    0.02687      0.474     0.8558          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:28<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.789      0.828      0.866      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      3.02G    0.02472     0.4624      0.857          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:29<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.797      0.823      0.867      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      3.02G        inf     0.4466     0.8547          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.801      0.819      0.867      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      3.02G        inf      0.434      0.853          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2301/2301 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.803      0.818      0.867      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 2.042 hours.\n",
      "Optimizer stripped from runs\\train\\mura_yolov8(25 epoch)73\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\train\\mura_yolov8(25 epoch)73\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\train\\mura_yolov8(25 epoch)73\\weights\\best.pt...\n",
      "Ultralytics 8.3.94  Python-3.10.11 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3197       3197      0.804      0.817      0.867      0.867\n",
      "     XR_ELBOW_negative        235        235      0.748      0.962      0.883      0.883\n",
      "     XR_ELBOW_positive        230        230       0.87      0.756      0.904      0.904\n",
      "    XR_FINGER_negative        214        214      0.707      0.893      0.814      0.814\n",
      "    XR_FINGER_positive        247        247      0.865       0.75        0.9        0.9\n",
      "   XR_FOREARM_negative        150        150      0.735      0.852      0.848      0.848\n",
      "   XR_FOREARM_positive        151        151      0.853      0.615      0.833      0.833\n",
      "      XR_HAND_negative        271        271      0.742      0.956      0.874      0.874\n",
      "      XR_HAND_positive        189        189      0.813      0.603      0.804      0.804\n",
      "   XR_HUMERUS_negative        148        148      0.875      0.797      0.889      0.889\n",
      "   XR_HUMERUS_positive        140        140      0.844      0.893      0.902      0.902\n",
      "  XR_SHOULDER_negative        285        285      0.745      0.877      0.847      0.847\n",
      "  XR_SHOULDER_positive        278        278      0.783      0.778       0.85       0.85\n",
      "     XR_WRIST_negative        364        364      0.786      0.956      0.901      0.901\n",
      "     XR_WRIST_positive        295        295      0.886      0.753      0.888      0.888\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\train\\mura_yolov8(25 epoch)73\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DetectionModel' object has no attribute 'resume'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train with checkpoint saving after every epoch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m      9\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMURA_YOLO/mura.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Dataset YAML file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,                   \u001b[38;5;66;03m# Number of epochs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     save_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                  \u001b[38;5;66;03m# Save model weights after every epoch\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:1156\u001b[0m, in \u001b[0;36mModel.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03m    Enable accessing model attributes directly through the Model class.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m        >>> print(model.names)  # Access model.names attribute\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DetectionModel' object has no attribute 'resume'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train with checkpoint saving after every epoch\n",
    "model.train(\n",
    "    data=\"MURA_YOLO/mura.yaml\",  # Dataset YAML file\n",
    "    epochs=25,                   # Number of epochs\n",
    "    imgsz=640,                   # Image size\n",
    "    batch=16,                     # Batch size\n",
    "    project=\"runs/train\",        # Project directory\n",
    "    name=\"mura_yolov8(25 epoch)7\", # Run name\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "    save=True,                    # Enable checkpoint saving\n",
    "    save_period=1                  # Save model weights after every epoch\n",
    ")\n",
    "model.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa78c5b-96d0-422a-9fda-44aaa8ed7e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 3197 true labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "valid_labels_dir = \"D:/Sem 6 project/MURA_YOLO/valid/labels\"\n",
    "y_true = []\n",
    "\n",
    "# Iterate through label files\n",
    "for label_file in os.listdir(valid_labels_dir):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(valid_labels_dir, label_file), \"r\") as f:\n",
    "            line = f.readline().strip()\n",
    "            class_id = int(line.split()[0])  # Extract class ID (first value)\n",
    "            y_true.append(class_id)\n",
    "\n",
    "print(f\"Extracted {len(y_true)} true labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37590a60-54a4-47c9-a159-fa3d2afc6f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of y_true: 3197, Length of y_pred: 3197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5837\n",
      "Specificity (Avg): 0.9676\n",
      "G-Mean: 0.7322\n",
      "AUC (ROC-AUC): 0.8115\n",
      "MCC: 0.5553\n",
      "Cohen's Kappa: 0.5469\n",
      "Log Loss: 1.7554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, confusion_matrix, log_loss\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Paths\n",
    "VALID_IMAGES_DIR = \"D:/Sem 6 project/MURA_YOLO/valid/images\"\n",
    "VALID_LABELS_DIR = \"D:/Sem 6 project/MURA_YOLO/valid/labels\"\n",
    "MODEL_PATH = \"D:/Sem 6 project/runs/train/mura_yolov8(25 epoch)7/weights/best.pt\"\n",
    "\n",
    "# Step 1: Extract ground truth\n",
    "y_true = []\n",
    "label_files = sorted([f for f in os.listdir(VALID_LABELS_DIR) if f.endswith(\".txt\")])\n",
    "for label_file in label_files:\n",
    "    with open(os.path.join(VALID_LABELS_DIR, label_file), \"r\") as f:\n",
    "        class_id = int(f.readline().strip().split()[0])\n",
    "        y_true.append(class_id)\n",
    "\n",
    "# Step 2: Extract predictions and scores\n",
    "model = YOLO(MODEL_PATH)\n",
    "image_files = sorted([os.path.join(VALID_IMAGES_DIR, f) for f in os.listdir(VALID_IMAGES_DIR) if f.endswith(\".png\")])\n",
    "batch_size = 8\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "y_scores_full = []\n",
    "\n",
    "for i in range(0, len(image_files), batch_size):\n",
    "    batch_files = image_files[i:i + batch_size]\n",
    "    results = model.predict(batch_files, save=False, imgsz=640, conf=0.1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", verbose=False)\n",
    "    \n",
    "    for result in results:\n",
    "        if len(result.boxes) > 0:\n",
    "            box = result.boxes[0]  # Highest confidence detection\n",
    "            pred_class = int(box.cls.item())\n",
    "            pred_score = box.conf.item()\n",
    "            y_pred.append(pred_class)\n",
    "            y_scores.append(pred_score)\n",
    "            scores = [pred_score if j == pred_class else (1 - pred_score) / (13) for j in range(14)]\n",
    "            y_scores_full.append(scores / np.sum(scores))\n",
    "        else:\n",
    "            print(f\"Warning: No detection for image {result.path}\")\n",
    "            y_pred.append(0)\n",
    "            y_scores.append(0.0)\n",
    "            y_scores_full.append([1.0 / 14] * 14)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Verify lengths\n",
    "print(f\"Length of y_true: {len(y_true)}, Length of y_pred: {len(y_pred)}\")\n",
    "assert len(y_true) == len(y_pred), \"Mismatch in lengths! Check image-label pairing.\"\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Explicitly extract scalar values\n",
    "precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "precision = precision.item() if hasattr(precision, 'item') else float(precision)\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "recall = recall.item() if hasattr(recall, 'item') else float(recall)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "f1 = f1.item() if hasattr(f1, 'item') else float(f1)\n",
    "\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# Specificity and G-mean\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "specificities = []\n",
    "for i in range(cm.shape[0]):\n",
    "    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "    fp = cm[:, i].sum() - cm[i, i]\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificities.append(specificity)\n",
    "specificity_avg = np.mean(specificities)\n",
    "g_mean = np.sqrt(recall * specificity_avg)\n",
    "\n",
    "# ROC AUC and Log Loss\n",
    "n_classes = 14\n",
    "class_names = ['XR_ELBOW_neg', 'XR_ELBOW_pos', 'XR_FINGER_neg', 'XR_FINGER_pos', \n",
    "               'XR_FOREARM_neg', 'XR_FOREARM_pos', 'XR_HAND_neg', 'XR_HAND_pos',\n",
    "               'XR_HUMERUS_neg', 'XR_HUMERUS_pos', 'XR_SHOULDER_neg', 'XR_SHOULDER_pos',\n",
    "               'XR_WRIST_neg', 'XR_WRIST_pos']\n",
    "y_true_bin = np.array([np.eye(n_classes)[label] for label in y_true])\n",
    "roc_auc = roc_auc_score(y_true_bin, y_scores_full, multi_class=\"ovr\", average=\"macro\")\n",
    "logloss = log_loss(y_true_bin, y_scores_full)\n",
    "\n",
    "# ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], [score[i] for score in y_scores_full])\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc_score(y_true_bin[:, i], [score[i] for score in y_scores_full]):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (One-vs-Rest)')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PR Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    precision, recall_pr, _ = precision_recall_curve(y_true_bin[:, i], [score[i] for score in y_scores_full])\n",
    "    plt.plot(recall_pr, precision, label=f'{class_names[i]}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves (One-vs-Rest)')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"Specificity (Avg): {specificity_avg:.4f}\")\n",
    "print(f\"G-Mean: {g_mean:.4f}\")\n",
    "print(f\"AUC (ROC-AUC): {roc_auc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1f01b0-50a6-46d0-bca2-e29748ad8876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of y_true: 3197, Length of y_pred: 3197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5837\n",
      "Precision: [   0.092274    0.092303    0.092332 ...           1           1           1]\n",
      "Recall: 0.5539817196650395\n",
      "F1 Score: 0.5175998154250524\n",
      "Specificity (Avg): 0.9676\n",
      "G-Mean: 0.7322\n",
      "AUC (ROC-AUC): 0.8115\n",
      "MCC: 0.5553\n",
      "Cohen's Kappa: 0.5469\n",
      "Log Loss: 1.7554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, confusion_matrix, log_loss\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Paths\n",
    "VALID_IMAGES_DIR = \"D:/Sem 6 project/MURA_YOLO/valid/images\"\n",
    "VALID_LABELS_DIR = \"D:/Sem 6 project/MURA_YOLO/valid/labels\"\n",
    "MODEL_PATH = \"D:/Sem 6 project/runs/train/mura_yolov8(25 epoch)7/weights/best.pt\"\n",
    "\n",
    "# Step 1: Extract ground truth\n",
    "y_true = []\n",
    "label_files = sorted([f for f in os.listdir(VALID_LABELS_DIR) if f.endswith(\".txt\")])\n",
    "for label_file in label_files:\n",
    "    with open(os.path.join(VALID_LABELS_DIR, label_file), \"r\") as f:\n",
    "        class_id = int(f.readline().strip().split()[0])\n",
    "        y_true.append(class_id)\n",
    "\n",
    "# Step 2: Extract predictions and scores\n",
    "model = YOLO(MODEL_PATH)\n",
    "image_files = sorted([os.path.join(VALID_IMAGES_DIR, f) for f in os.listdir(VALID_IMAGES_DIR) if f.endswith(\".png\")])\n",
    "batch_size = 8\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "y_scores_full = []\n",
    "\n",
    "for i in range(0, len(image_files), batch_size):\n",
    "    batch_files = image_files[i:i + batch_size]\n",
    "    results = model.predict(batch_files, save=False, imgsz=640, conf=0.1, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", verbose=False)\n",
    "    \n",
    "    for result in results:\n",
    "        if len(result.boxes) > 0:\n",
    "            box = result.boxes[0]  # Highest confidence detection\n",
    "            pred_class = int(box.cls.item())\n",
    "            pred_score = box.conf.item()\n",
    "            y_pred.append(pred_class)\n",
    "            y_scores.append(pred_score)\n",
    "            scores = [pred_score if j == pred_class else (1 - pred_score) / (13) for j in range(14)]\n",
    "            y_scores_full.append(scores / np.sum(scores))\n",
    "        else:\n",
    "            print(f\"Warning: No detection for image {result.path}\")\n",
    "            y_pred.append(0)\n",
    "            y_scores.append(0.0)\n",
    "            y_scores_full.append([1.0 / 14] * 14)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Verify lengths\n",
    "print(f\"Length of y_true: {len(y_true)}, Length of y_pred: {len(y_pred)}\")\n",
    "assert len(y_true) == len(y_pred), \"Mismatch in lengths! Check image-label pairing.\"\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Explicitly convert to float\n",
    "precision = float(precision_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "recall = float(recall_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "f1 = float(f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# Specificity and G-mean\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "specificities = []\n",
    "for i in range(cm.shape[0]):\n",
    "    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "    fp = cm[:, i].sum() - cm[i, i]\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificities.append(specificity)\n",
    "specificity_avg = np.mean(specificities)\n",
    "g_mean = np.sqrt(recall * specificity_avg)\n",
    "\n",
    "# ROC AUC and Log Loss\n",
    "n_classes = 14\n",
    "class_names = ['XR_ELBOW_neg', 'XR_ELBOW_pos', 'XR_FINGER_neg', 'XR_FINGER_pos', \n",
    "               'XR_FOREARM_neg', 'XR_FOREARM_pos', 'XR_HAND_neg', 'XR_HAND_pos',\n",
    "               'XR_HUMERUS_neg', 'XR_HUMERUS_pos', 'XR_SHOULDER_neg', 'XR_SHOULDER_pos',\n",
    "               'XR_WRIST_neg', 'XR_WRIST_pos']\n",
    "y_true_bin = np.array([np.eye(n_classes)[label] for label in y_true])\n",
    "roc_auc = float(roc_auc_score(y_true_bin, y_scores_full, multi_class=\"ovr\", average=\"macro\"))\n",
    "logloss = float(log_loss(y_true_bin, y_scores_full))\n",
    "\n",
    "# ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], [score[i] for score in y_scores_full])\n",
    "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {float(roc_auc_score(y_true_bin[:, i], [score[i] for score in y_scores_full])):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (One-vs-Rest)')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PR Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    precision, recall_pr, _ = precision_recall_curve(y_true_bin[:, i], [score[i] for score in y_scores_full])\n",
    "    plt.plot(recall_pr, precision, label=f'{class_names[i]}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves (One-vs-Rest)')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity (Avg): {specificity_avg:.4f}\")\n",
    "print(f\"G-Mean: {g_mean:.4f}\")\n",
    "print(f\"AUC (ROC-AUC): {roc_auc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c66fb1-7574-44f3-add6-a25a3f635ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
